

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Installation &mdash; valis &#34;1.0.0rc11&#34;
 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: black" >
          

          
            <a href="index.html">
          

          
            
            <img src="_static/valis_logo_black_no_bg.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="registration.html">Registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="slide_io.html">Slide I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="preprocessing.html">Image pre-processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_detectors.html">Feature detectors and descriptors</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_matcher.html">Feature matching</a></li>
<li class="toctree-l1"><a class="reference internal" href="affine_optimizer.html">Affine optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="non_rigid_registrars.html">Non-rigid registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="serial_rigid.html">Serial rigid registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="serial_non_rigid.html">Serial non-rigid registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="viz.html">Visualization</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">valis</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Installation</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/README.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <p><a class="reference external" href="https://valis.readthedocs.io/en/latest/?badge=latest"><img alt="Documentation Status" src="https://readthedocs.org/projects/valis/badge/?version=latest" /></a> <a class="reference external" href="https://github.com/MathOnco/valis/actions?workflow=CI"><img alt="CI Status" src="https://github.com/MathOnco/valis/workflows/CI/badge.svg?branch=main" /></a> <a class="reference external" href="https://badge.fury.io/py/valis-wsi"><img alt="pypi" src="https://badge.fury.io/py/valis-wsi.svg" /></a></p>
<img alt="https://github.com/MathOnco/valis/raw/main/docs/_images/banner.gif" src="https://github.com/MathOnco/valis/raw/main/docs/_images/banner.gif" />
<p>VALIS, which stands for Virtual Alignment of pathoLogy Image Series, is a fully automaated pipeline to register whole slide images (WSI) using rigid and/or non-rigid transformtions. A full description of the method is descriped in the paper by <a class="reference external" href="https://www.biorxiv.org/content/10.1101/2021.11.09.467917v1">Gatenbee et al. 2021</a>. VALIS uses <a class="reference external" href="https://www.openmicroscopy.org/bio-formats/">Bio-Formats</a>, <a class="reference external" href="https://openslide.org/">OpenSlide</a>, <a class="reference external" href="https://www.libvips.org/">libvips</a>, and <a class="reference external" href="https://scikit-image.org/">scikit-image</a> to read images and slides, and so is able to work with over 300 image formats. Registered images can be saved as <a class="reference external" href="https://docs.openmicroscopy.org/ome-model/5.6.3/ome-tiff/">ome.tiff</a> slides that can be used in downstream analyses. ome.tiff format is opensource and widely supported, being readable in several different programming languages (Python, Java, Matlab, etc…) and software, such as <a class="reference external" href="https://qupath.github.io/">QuPath</a>, <a class="reference external" href="https://indicalab.com/halo/">HALO by Idica Labs</a>, etc…</p>
<p>The registration pipeline is fully automated and goes as follows:</p>
<blockquote>
<div><blockquote>
<div><img alt="https://github.com/MathOnco/valis/raw/main/docs/_images/pipeline.png" src="https://github.com/MathOnco/valis/raw/main/docs/_images/pipeline.png" />
</div></blockquote>
<ol class="arabic">
<li><p>Images/slides are converted to numpy arrays. As WSI are often too large to fit into memory, these images are usually lower resolution images from different pyramid levels.</p></li>
<li><p>Images are processed to single channel images. They are then normalized to make them look as similar as possible. Masks are then created to focus registration on the tissue.</p></li>
<li><p>Image features are detected and then matched between all pairs of image.</p></li>
<li><p>If the order of images is unknown, they will be optimally ordered based on their feature similarity. This increases the chances of successful registration because each image will be aligned to one that looks very similar.</p></li>
<li><p>Images will be aligned <em>towards</em> (not to) a reference image. If the reference image is not specified, it will automatically be set to the image at the center of the stack.</p></li>
<li><p>Rigid registration is performed serially, with each image being rigidly aligned towards the reference image. That is, if the reference image is the 5th in the stack, image 4 will be aligned to 5 (the reference), and then 3 will be aligned to the now registered version of 4, and so on. Only features found in both neighboring slides are used to align the image to the next one in the stack. VALIS uses feature detection to match and align images, but one can optionally perform a final step that maximizes the mutual information betweeen each pair of images.</p></li>
<li><p>The registered rigid masks are combined to create a non-rigid registration mask. The bounding box of this mask is then used to extract higher resolution versions of the tissue from each slide. These higher resolution images are then processed as above and used for non-rigid registration, which is performed either by:</p>
<blockquote>
<div><ul class="simple">
<li><p>aliging each image towards the reference image following the same sequence used during rigid registation.</p></li>
<li><p>using groupwise registration that non-rigidly aligns the images to a common frame of reference. Currently this is only possible if <a class="reference external" href="https://simpleelastix.github.io">SimpleElastix</a> is installed.</p></li>
</ul>
</div></blockquote>
</li>
<li><p>One can optionally perform a second non-rigid registration using an even higher resolution versions of each image. This is intended to better align micro-features not visible in the original images, and so is referred to as micro-registration. A mask can also be used to indicate where registration should take place.</p></li>
<li><p>Error is estimated by calculating the distance between registered matched features in the full resolution images.</p></li>
</ol>
</div></blockquote>
<p>The transformations found by VALIS can then be used to warp the full resolution slides. It is also possible to merge non-RGB registered slides to create a highly multiplexed image. These aligned and/or merged slides can then be saved as ome.tiff images. The transformations can also be use to warp point data, such as cell centroids, polygon vertices, etc…</p>
<p>In addition to registering images, VALIS provides tools to read slides using Bio-Formats and OpenSlide, which can be read at multiple resolutions and converted to numpy arrays or pyvips.Image objects. One can also slice regions of interest from these slides and warp annotated images. VALIS also provides functions to convert slides to the ome.tiff format, preserving the original metadata. Please see examples and documentation for more details.</p>
<p>Full documentation can be found at <a class="reference external" href="https://valis.readthedocs.io/en/latest/">ReadTheDocs</a>.</p>
<div class="contents local topic" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#installation" id="id4">Installation</a></p></li>
<li><p><a class="reference internal" href="#examples" id="id5">Examples</a></p></li>
<li><p><a class="reference internal" href="#change-log" id="id6">Change Log</a></p></li>
</ul>
</div>
<section id="installation">
<h1><a class="toc-backref" href="#id4">Installation</a><a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>VALIS requires Python &gt;=3.7</p>
</div>
<section id="conda-recommened-for-non-windows-users">
<h2>conda (recommened for non-Windows users)<a class="headerlink" href="#conda-recommened-for-non-windows-users" title="Permalink to this headline">¶</a></h2>
<p>VALIS will soon be available in the conda-forge channel of conda. However, unfortunately <a class="reference external" href="https://www.libvips.org/">libvips</a>, a  core dependency, is not yet available for Windows users on conda-forge.</p>
</section>
<section id="pip">
<h2>pip<a class="headerlink" href="#pip" title="Permalink to this headline">¶</a></h2>
<p>VALIS can be downloaded from PyPI as the <a class="reference external" href="https://pypi.org/project/valis-wsi/#description">valis-wsi</a> package using the pip command. However, VALIS requires several system level packages, which will need to be installed first.</p>
<section id="prerequisites">
<h3>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h3>
<p>VALIS uses Bioforamts to read many slide formats. Bioformats is written in Java, and VALIS uses the Python package jpype to access the Bioformats jar. Therefore, the user will need to have installed a Java Development Kit (JDK) containing the Java Runtime Environment (JRE):</p>
<ol class="arabic">
<li><p>Download appropriate JDK from <a class="reference external" href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">java downloads</a></p></li>
<li><p>Edit your system and environment variables to update the Java home</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">export</span> <span class="nv">JAVA_HOME</span><span class="o">=</span>/usr/libexec/java_home
</pre></div>
</div>
</li>
<li><p>Verify the path has been added:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">echo</span> <span class="nv">$JAVA_HOME</span>
</pre></div>
</div>
<p>should print something like <code class="code docutils literal notranslate"><span class="pre">usr/libexec/java_home</span></code></p>
</li>
<li><p>(optional) If you will be working with files that have extensions: ‘.vmu’, ‘.mrxs’ ‘.svslide’, you will also need to install <a class="reference external" href="https://openslide.org">OpenSlide</a>. Note that this is not the same as openslide-python, which contains Python wrappers for OpenSlide.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>OpenSlide requires <a class="reference external" href="http://www.pixman.org">pixman</a>, which must be version 0.40.0. If pixman is a different version, then the slides may be distorted when reading from any pyramid level other than 0.</p>
</div>
</li>
<li><p>VALIS uses <a class="reference external" href="https://github.com/libvips/pyvips">pyvips</a> to warp and save the whole slide images (WSI) as ome.tiffs. Pyvips requires <a class="reference external" href="https://www.libvips.org/">libvips</a> (not a Python package) to be on your library search path, and so libvips must be installed separately. See the <a class="reference external" href="https://github.com/libvips/pyvips/blob/master/README.rst#non-conda-install">pyvips installation notes</a> for instructions on how to do this for your operating system. If you already have libvips installed, please make sure it’s version is &gt;= 8.11.</p></li>
</ol>
</section>
<section id="install">
<h3>Install<a class="headerlink" href="#install" title="Permalink to this headline">¶</a></h3>
<p>Once the above prerequisites have been satistifed, valis can be installed using pip, idealy within a virtual environment</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python3 -m venv venv_valis
$ <span class="nb">source</span> ./venv_valis/bin/activate
$ python3 -m pip install --upgrade pip
$ python3 pip install valis-wsi
</pre></div>
</div>
</section>
</section>
<section id="simpleelastix-optional">
<h2>SimpleElastix (optional)<a class="headerlink" href="#simpleelastix-optional" title="Permalink to this headline">¶</a></h2>
<p>The defaults used by VALIS work well, but VALIS also provides optional classes that require <a class="reference external" href="https://simpleelastix.github.io">SimpleElastix</a>. In particular, these classes are:</p>
<ol class="arabic simple">
<li><p>affine_optimizer.AffineOptimizerMattesMI, which uses sitk.ElastixImageFilter to simultaneously maximize Mattes Mutual Information and minimize the spatial distance between matched features.</p></li>
<li><p>non_rigid_registrars.SimpleElastixWarper, which uses sitk.ElastixImageFilter to find non-rigid transformations between pairs of images.</p></li>
<li><p>non_rigid_registrars.SimpleElastixGroupwiseWarper, which uses sitk.ElastixImageFilter to find non-rigid transformations using groupwise registration.</p></li>
</ol>
<p>To install SimpleElastix, you should probably uninstall the current version of SimpleITK in your environment, and then install SimpleElastix as described in the <a class="reference external" href="https://simpleelastix.readthedocs.io/GettingStarted.html">SimpleElastix docs</a>.</p>
</section>
</section>
<section id="examples">
<h1><a class="toc-backref" href="#id5">Examples</a><a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h1>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Always be sure to always kill the JVM at the end of your script. Not doing so can prevent the software from closing. This can be accomplished by calling  either <code class="code docutils literal notranslate"><span class="pre">registration.kill_jvm()</span></code> or <code class="code docutils literal notranslate"><span class="pre">slide_io.kill_jvm()</span></code></p>
</div>
<section id="slide-registration">
<h2>Slide registration<a class="headerlink" href="#slide-registration" title="Permalink to this headline">¶</a></h2>
<img alt="https://github.com/MathOnco/valis/raw/main/docs/_images/challenging_dataset_adincar33.png" src="https://github.com/MathOnco/valis/raw/main/docs/_images/challenging_dataset_adincar33.png" />
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>One of the most imporant parameters used to initialize a Valis object is <code class="code docutils literal notranslate"><span class="pre">max_processed_image_dim_px</span></code>. The default value is 850, but if registration fails or is poor, try adjusting that value. Generally speaking, values between 500-2000 work well. In cases where there is little empty space, around the tissue, smaller values may be better. However, if there is a large amount of empty space/slide (as in the images above), larger values will be needed so that the tissue is at a high enough resolution. Finally, larger values can potentially generate more accurate registrations, but will be slower, require more memory, and won’t always produce better results.</p>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>If the order of slices is known and needs to be preserved, such as building a 3D image, set <code class="code docutils literal notranslate"><span class="pre">imgs_ordered=True</span></code> when intialzing the VALIS object. Otherwise, VALIS will sort the images based on similarity, which may or may not correspond on the sliced order. If using this option, be sure that the names of the files allow them to be sorted properly, e.g. 01.tiff, 02.tiff … 10.tiff, etc…</p>
</div>
<p>In this example, the slides that need to be registered are located in <code class="code docutils literal notranslate"><span class="pre">/path/to/slides</span></code>. This process involves creating a Valis object, which is what conducts the registration. In this example no reference image is specfied, and so all images will be aligned towards the center of the image stack. In this case, the resulting images will be cropped to the region where all of the images overlap. However, one can specify the reference image when intialzing the <code class="code docutils literal notranslate"><span class="pre">Valis</span></code> object, by setting <code class="code docutils literal notranslate"><span class="pre">reference_img_f</span></code> to the filename of the image the others should be aligned towards. When the reference image is specifed, the images will be cropped such that only the regions which overlap with the reference image will be saved. While this is the default behavior, one can also specify the cropping method by setting the <code class="code docutils literal notranslate"><span class="pre">crop</span></code> parameter value when initialzing the <code class="code docutils literal notranslate"><span class="pre">Valis</span></code> object. The cropping method can also be changed when saving the registered images (see below).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">valis</span> <span class="kn">import</span> <span class="n">registration</span>
<span class="n">slide_src_dir</span> <span class="o">=</span> <span class="s2">&quot;/path/to/slides&quot;</span>
<span class="n">results_dst_dir</span> <span class="o">=</span> <span class="s2">&quot;./slide_registration_example&quot;</span>
<span class="n">registered_slide_dst_dir</span> <span class="o">=</span> <span class="s2">&quot;./slide_registration_example/registered_slides&quot;</span>

<span class="c1"># Create a Valis object and use it to register the slides in slide_src_dir</span>
<span class="n">registrar</span> <span class="o">=</span> <span class="n">registration</span><span class="o">.</span><span class="n">Valis</span><span class="p">(</span><span class="n">slide_src_dir</span><span class="p">,</span> <span class="n">results_dst_dir</span><span class="p">)</span>
<span class="n">rigid_registrar</span><span class="p">,</span> <span class="n">non_rigid_registrar</span><span class="p">,</span> <span class="n">error_df</span> <span class="o">=</span> <span class="n">registrar</span><span class="o">.</span><span class="n">register</span><span class="p">()</span>
</pre></div>
</div>
<p>The next example shows how align each image to a reference image, followed up by micro-registration. The reference image the others should be aligned towards is set with the <code class="code docutils literal notranslate"><span class="pre">reference_img_f</span></code> argument when initialzing the <code class="code docutils literal notranslate"><span class="pre">Valis</span></code> object. This initial registration is followed up by micro-registration in order to better align features that were not present in the smaller images used for the first registration (The size of the images used for micro-registration can is set with the <code class="code docutils literal notranslate"><span class="pre">max_non_rigid_registartion_dim_px</span></code> argument in <code class="code docutils literal notranslate"><span class="pre">Valis.register_micro</span></code>). Setting <code class="code docutils literal notranslate"><span class="pre">align_to_reference</span></code> to <cite>True</cite> will align each image directly <em>to</em> the reference image, as opposed to <em>towards</em> it.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">valis</span> <span class="kn">import</span> <span class="n">registration</span>
<span class="n">slide_src_dir</span> <span class="o">=</span> <span class="s2">&quot;/path/to/slides&quot;</span>
<span class="n">results_dst_dir</span> <span class="o">=</span> <span class="s2">&quot;./slide_registration_example&quot;</span>
<span class="n">registered_slide_dst_dir</span> <span class="o">=</span> <span class="s2">&quot;./slide_registration_example/registered_slides&quot;</span>
<span class="n">reference_slide</span> <span class="o">=</span> <span class="s2">&quot;HE.tiff&quot;</span>

<span class="c1"># Create a Valis object and use it to register the slides in slide_src_dir, aligning towards the reference slide.</span>
<span class="n">registrar</span> <span class="o">=</span> <span class="n">registration</span><span class="o">.</span><span class="n">Valis</span><span class="p">(</span><span class="n">slide_src_dir</span><span class="p">,</span> <span class="n">results_dst_dir</span><span class="p">,</span> <span class="n">reference_img_f</span><span class="o">=</span><span class="n">reference_slide</span><span class="p">)</span>
<span class="n">rigid_registrar</span><span class="p">,</span> <span class="n">non_rigid_registrar</span><span class="p">,</span> <span class="n">error_df</span> <span class="o">=</span> <span class="n">registrar</span><span class="o">.</span><span class="n">register</span><span class="p">()</span>

<span class="c1"># Perform micro-registration on higher resolution images, aligning directly to the reference image</span>
<span class="n">registrar</span><span class="o">.</span><span class="n">register_micro</span><span class="p">(</span><span class="n">max_non_rigid_registartion_dim_px</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">align_to_reference</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>After registration is complete, one can view the results to determine if they are acceptable. In this example, the results are located in  <code class="code docutils literal notranslate"><span class="pre">./slide_registration_example</span></code>. Inside this folder will be 6 subfolders:</p>
<ol class="arabic simple">
<li><p><strong>data</strong> contains 2 files:</p>
<ul class="simple">
<li><p>a summary spreadsheet of the alignment results, such as the registration error between each pair of slides, their dimensions, physical units, etc…</p></li>
<li><p>a pickled version of the registrar. This can be reloaded (unpickled) and used later. For example, one could perfom the registration locally, but then use the pickled object to warp and save the slides on an HPC. Or, one could perform the registration and use the registrar later to warp points found in the (un-registered) slide.</p></li>
</ul>
</li>
<li><p><strong>overlaps</strong> contains thumbnails showing the how the images would look if stacked without being registered, how they look after rigid registration, and how they look after non-rigid registration. The rightmost images in the figure above provide examples of these overlap images.</p></li>
<li><p><strong>rigid_registration</strong> shows thumbnails of how each image looks after performing rigid registration. These would be similar to the bottom row in the figure above.</p></li>
<li><p><strong>non_rigid_registration</strong> shows thumbnaials of how each image looks after non-rigid registration. These would be similar to the bottom row in the figure above.</p></li>
<li><p><strong>deformation_fields</strong> contains images showing what the non-rigid deformation would do to a triangular mesh. These can be used to get a sense of how the images were altered by non-rigid warping. In these images, the color indicates the direction of the displacement, while brightness indicates it’s magnitude. These would be similar to those in the middle row in the figure above.</p></li>
<li><p><strong>processed</strong> shows thumnails of the processed images. These are thumbnails of the images that were actually used to perform the registration. The pre-processing and normalization methods should try to make these images look as similar as possible.</p></li>
<li><p><strong>masks</strong> show the images with outlines of their rigid registration mask drawn around them. If non-rigid registration is being performed, there will also be an image of the reference image with the non-rigid registration mask drawn around it.</p></li>
</ol>
<p>If the results look good, then one can warp and save all of the slides as ome.tiffs. When saving the images, there are three cropping options:</p>
<ol class="arabic simple">
<li><p><code class="code docutils literal notranslate"><span class="pre">crop=&quot;overlap&quot;</span></code> will crop the images to the region where all of the images overlap.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">crop=&quot;reference&quot;</span></code> will crop the images to the region where they overlap with the reference image.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">crop=&quot;all&quot;</span></code> will not perform any cropping. While this keep the all of the image, the dimensions of the registered image can be substantially larger than one that was cropped, as it will need to be large enough accomodate all of the other images.</p></li>
</ol>
<p>While the cropping setting can also be set when initializing the <code class="code docutils literal notranslate"><span class="pre">Valis</span></code> object, any of the above cropping methods can be used when saving the images.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Save all registered slides as ome.tiff</span>
<span class="n">registrar</span><span class="o">.</span><span class="n">warp_and_save_slides</span><span class="p">(</span><span class="n">registered_slide_dst_dir</span><span class="p">,</span> <span class="n">crop</span><span class="o">=</span><span class="s2">&quot;overlap&quot;</span><span class="p">)</span>

<span class="c1"># Kill the JVM</span>
<span class="n">registration</span><span class="o">.</span><span class="n">kill_jvm</span><span class="p">()</span>
</pre></div>
</div>
<p>The ome.tiff images can subsequently be used for downstream analysis, such as <a class="reference external" href="https://qupath.github.io/">QuPath</a></p>
<img alt="https://github.com/MathOnco/valis/raw/main/docs/_images/ome_tiff_zoom.png" src="https://github.com/MathOnco/valis/raw/main/docs/_images/ome_tiff_zoom.png" />
<p>One can also choose to save individual slides. This is accomplished by accessing the Slide object associated with a particular file, <code class="code docutils literal notranslate"><span class="pre">slide_f</span></code> and then “telling” it to save the slide as <code class="code docutils literal notranslate"><span class="pre">out_f.ome.tiff</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">slide_obj</span> <span class="o">=</span> <span class="n">registrar</span><span class="o">.</span><span class="n">get_slide</span><span class="p">(</span><span class="n">slide_f</span><span class="p">)</span>
<span class="n">slide_obj</span><span class="o">.</span><span class="n">warp_and_save_slide</span><span class="p">(</span><span class="s2">&quot;out_f.ome.tiff&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Finally, if the non-rigid registration is deemed to have distored the image too much, one can apply only the rigid transformation by setting <code class="code docutils literal notranslate"><span class="pre">non_rigid=False</span></code> in <code class="code docutils literal notranslate"><span class="pre">slide_obj.warp_and_save_slide</span></code> or <code class="code docutils literal notranslate"><span class="pre">registrar.warp_and_save_slides</span></code>.</p>
</section>
<section id="create-multiplex-image-from-immunofluorescence-images">
<h2>Create multiplex image from immunofluorescence images<a class="headerlink" href="#create-multiplex-image-from-immunofluorescence-images" title="Permalink to this headline">¶</a></h2>
<p>Following registration, VALIS can merge the slides to create a single composite image. However, this should only be done for non-RGB images, such as multi/single-channel immunofluorescence images. An example would be slides of multiple CyCIF rounds. The user also has the option to provide channel names, but if not provided the channel names will become the “channel (filename)” given the channel name in the metadata. For example, if the file name is round1.ndpis then the DAPI channel name will be “DAPI (round1)”). In this example, the channel names are taken from the filename, which have the form “Tris CD20 FOXP3 CD3.ndpis”, “Tris CD4 CD68 CD3 1in25 ON.ndpis”, etc… The channel names need to be in a dictionary, where key=filename, value = list of channel names.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>By default, if a channel occurs in more than 1 image, only the 1st instance will be merged. For example, if DAPI is in all images, then only the DAPI channel of the 1st image will be in the resulting slide. This can be disabled by setting <code class="code docutils literal notranslate"><span class="pre">drop_duplicates=False</span></code> in <code class="code docutils literal notranslate"><span class="pre">warp_and_merge_slides</span></code></p>
</div>
<p>First, create a VALIS object and use it to register slides located in <code class="code docutils literal notranslate"><span class="pre">slide_src_dir</span></code></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">valis</span> <span class="kn">import</span> <span class="n">registration</span>
<span class="n">slide_src_dir</span> <span class="o">=</span> <span class="s2">&quot;/path/to/slides&quot;</span>
<span class="n">results_dst_dir</span> <span class="o">=</span> <span class="s2">&quot;./slide_merging_example&quot;</span>  <span class="c1"># Registration results saved here</span>
<span class="n">merged_slide_dst_f</span> <span class="o">=</span> <span class="s2">&quot;./slide_merging_example/merged_slides.ome.tiff&quot;</span>  <span class="c1"># Where to save merged slide</span>

<span class="n">registrar</span> <span class="o">=</span> <span class="n">registration</span><span class="o">.</span><span class="n">Valis</span><span class="p">(</span><span class="n">slide_src_dir</span><span class="p">,</span> <span class="n">results_dst_dir</span><span class="p">)</span>
<span class="n">rigid_registrar</span><span class="p">,</span> <span class="n">non_rigid_registrar</span><span class="p">,</span> <span class="n">error_df</span> <span class="o">=</span> <span class="n">registrar</span><span class="o">.</span><span class="n">register</span><span class="p">()</span>
</pre></div>
</div>
<p>Check the results in <code class="code docutils literal notranslate"><span class="pre">results_dst_dir</span></code>, and if the look good merge and save the slide. Once complete, be sure to kill the JVM.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create function to extract channel names from the image.</span>
<span class="k">def</span> <span class="nf">cnames_from_filename</span><span class="p">(</span><span class="n">src_f</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get channel names from file name</span>
<span class="sd">    Note that the DAPI channel is not part of the filename</span>
<span class="sd">    but is always the first channel.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">f</span> <span class="o">=</span> <span class="n">valtils</span><span class="o">.</span><span class="n">get_name</span><span class="p">(</span><span class="n">src_f</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;DAPI&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">f</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span>

<span class="n">channel_name_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">f</span><span class="p">:</span><span class="n">cnames_from_filename</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">registrar</span><span class="o">.</span><span class="n">original_img_list</span><span class="p">}</span>
<span class="n">merged_img</span><span class="p">,</span> <span class="n">channel_names</span><span class="p">,</span> <span class="n">ome_xml</span> <span class="o">=</span> \
    <span class="n">registrar</span><span class="o">.</span><span class="n">warp_and_merge_slides</span><span class="p">(</span><span class="n">merged_slide_dst_f</span><span class="p">,</span>
                                    <span class="n">channel_name_dict</span><span class="o">=</span><span class="n">channel_name_dict</span><span class="p">,</span>
                                    <span class="n">drop_duplicates</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">registration</span><span class="o">.</span><span class="n">kill_jvm</span><span class="p">()</span> <span class="c1"># Kill the JVM</span>
</pre></div>
</div>
<img alt="https://github.com/MathOnco/valis/raw/main/docs/_images/merge_ome_tiff.png" src="https://github.com/MathOnco/valis/raw/main/docs/_images/merge_ome_tiff.png" />
</section>
<section id="warping-points">
<h2>Warping points<a class="headerlink" href="#warping-points" title="Permalink to this headline">¶</a></h2>
<p>Once the registration parameters have been found, VALIS can be used to warp point data, such as cell coordinates, mask polygon vertices, etc… In this example, slides will be registered, and the registration parameters will then be used warp cell positions located in a separate .csv. This accomplished by accessing the <code class="code docutils literal notranslate"><span class="pre">Slide</span></code> object associated with each registered slide. This is done by passing the slide’s filename (with or without the extension) to <code class="code docutils literal notranslate"><span class="pre">registrar.get_slide</span></code>. This <code class="code docutils literal notranslate"><span class="pre">Slide</span></code> object can the be used to warp the individual slide and/or points associated with the un-registered slide. This can be useful in cases where one has already performed an analysis on the un-registered slides, as one can just warp the point data, as opposed to warping each slide and re-conducting the analysis.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>It is essential that the image from which the coordinates are derived has the same aspect ratio as the image used for registration. That is, the images used for registration must be scaled up/down versions of the image from which the coordinates are taken. For example, registration may be performed on lower resolution images (an upper image pyramid level), and applied to cell coordinates found by performing cell segmenation on the full resolution (pyramid level 0) image. The default is to assume that the points came from the highest resolution image, but this can be changed by setting <code class="code docutils literal notranslate"><span class="pre">pt_level</span></code> to either the pyramid level of the image the points originated, or its dimensions (width, height, in pixels). Also, the coordinates need to be in pixel units, not physical units. Finally, be sure that the coordinates are X,Y (column, row), with the origin being the top left corner of the image.</p>
</div>
<p>In this first example, cell segmentation and phenotyping has already been performed on the unregistered images. We can now use the <code class="code docutils literal notranslate"><span class="pre">Valis</span></code> object that performed the registration to warp the cell positions to their location in the registered images.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">valis</span> <span class="kn">import</span> <span class="n">registration</span>

<span class="n">slide_src_dir</span> <span class="o">=</span> <span class="s2">&quot;path/to/slides&quot;</span>
<span class="n">point_data_dir</span> <span class="o">=</span> <span class="s2">&quot;path/to/cell_positions&quot;</span>
<span class="n">results_dst_dir</span> <span class="o">=</span> <span class="s2">&quot;./point_warping_example&quot;</span>

<span class="c1"># Load a Valis object that has already registered the images.</span>
<span class="n">registrar_f</span> <span class="o">=</span> <span class="s2">&quot;path/to/results/data/registrar.pickle&quot;</span>
<span class="n">registrar</span> <span class="o">=</span> <span class="n">registration</span><span class="o">.</span><span class="n">load_registrar</span><span class="p">(</span><span class="n">registrar_f</span><span class="p">)</span>

<span class="c1"># Get .csv files containing cell coordinates</span>
<span class="n">point_data_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">point_data_dir</span><span class="p">)</span><span class="o">.</span><span class="n">rglob</span><span class="p">(</span><span class="s2">&quot;*.csv&quot;</span><span class="p">))</span>

<span class="c1"># Go through each file and warp the cell positions</span>
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">point_data_list</span><span class="p">:</span>
    <span class="c1"># Get Slide object associated with the slide from which the point data originated</span>
    <span class="c1"># Point data and image have similar file names</span>
    <span class="n">fname</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">f</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">corresponding_img</span> <span class="o">=</span> <span class="n">fname</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.tif&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">slide_obj</span> <span class="o">=</span> <span class="n">registrar</span><span class="o">.</span><span class="n">get_slide</span><span class="p">(</span><span class="n">corresponding_img</span><span class="p">)</span>

    <span class="c1"># Read data and calculate cell centroids (x, y)</span>
    <span class="n">points_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">points_df</span><span class="p">[[</span><span class="s2">&quot;XMin&quot;</span><span class="p">,</span> <span class="s2">&quot;XMax&quot;</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">points_df</span><span class="p">[[</span><span class="s2">&quot;YMin&quot;</span><span class="p">,</span> <span class="s2">&quot;YMax&quot;</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
    <span class="n">xy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Use Slide to warp the coordinates</span>
    <span class="n">warped_xy</span> <span class="o">=</span> <span class="n">slide_obj</span><span class="o">.</span><span class="n">warp_xy</span><span class="p">(</span><span class="n">xy</span><span class="p">)</span>

    <span class="c1"># Update dataframe with registered cell centroids</span>
    <span class="n">points_df</span><span class="p">[[</span><span class="s2">&quot;registered_x&quot;</span><span class="p">,</span> <span class="s2">&quot;registered_y&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">warped_xy</span>

    <span class="c1"># Save updated dataframe</span>
    <span class="n">pt_f_out</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">f</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;.csv&quot;</span><span class="p">,</span> <span class="s2">&quot;_registered.csv&quot;</span><span class="p">)</span>
    <span class="n">full_pt_f_out</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">results_dst_dir</span><span class="p">,</span> <span class="n">pt_f_out</span><span class="p">)</span>
    <span class="n">points_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">full_pt_f_out</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">registration</span><span class="o">.</span><span class="n">kill_jvm</span><span class="p">()</span> <span class="c1"># Kill the JVM</span>
</pre></div>
</div>
<p>Here is a comparison of before and after applying registration to cell positions found in the original un-aligned images:</p>
<img alt="https://github.com/MathOnco/valis/raw/main/docs/_images/point_warping.png" src="https://github.com/MathOnco/valis/raw/main/docs/_images/point_warping.png" />
<p>In this second example, a region of interest (ROI) was marked in one of the unregistered images, in this case “ihc_2.ome.tiff” . Using the <code class="code docutils literal notranslate"><span class="pre">Slide</span></code> object associated with “ihc_2.ome.tiff”, we can warp those ROI coordinates to their position in the registered images, and then use those to slice the registered ROI from each slide. Because VALIS uses pyvips to read and warp the slides, this process does not require the whole image to be loaded into memory and warped. As such, this is fast and does not require much memory. It’s also worth noting that because the points are being warped to the registred coordinate system, the slide that is the source of the ROI coordinates does not have to be the same slide that was treated as the reference image during registration.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">from</span> <span class="nn">valis</span> <span class="kn">import</span> <span class="n">registration</span><span class="p">,</span> <span class="n">warp_tools</span>

<span class="c1"># Load a registrar that has already registered the images.</span>
<span class="n">registrar_f</span> <span class="o">=</span> <span class="s2">&quot;./expected_results/registration/ihc/data/ihc_registrar.pickle&quot;</span>
<span class="n">registrar</span> <span class="o">=</span> <span class="n">registration</span><span class="o">.</span><span class="n">load_registrar</span><span class="p">(</span><span class="n">registrar_f</span><span class="p">)</span>
<span class="c1"># Set the pyramid level from which the ROI coordinates originated. Usually 0 when working with slides.</span>
<span class="n">COORD_LEVEL</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># ROI coordinates, in microns. These came from the unregistered slide, &quot;ihc_2.ome.tiff&quot;</span>
<span class="n">bbox_xywh_um</span> <span class="o">=</span> <span class="p">[</span><span class="mi">14314</span><span class="p">,</span> <span class="mi">13601</span><span class="p">,</span> <span class="mi">3000</span><span class="p">,</span> <span class="mi">3000</span><span class="p">]</span>
<span class="n">bbox_xy_um</span> <span class="o">=</span> <span class="n">warp_tools</span><span class="o">.</span><span class="n">bbox2xy</span><span class="p">(</span><span class="n">bbox_xywh_um</span><span class="p">)</span>

<span class="c1"># Get slide from which the ROI coordinates originated</span>
<span class="n">pt_source_img_f</span> <span class="o">=</span> <span class="s2">&quot;ihc_2.ome.tiff&quot;</span>
<span class="n">pt_source_slide</span> <span class="o">=</span> <span class="n">registrar</span><span class="o">.</span><span class="n">get_slide</span><span class="p">(</span><span class="n">pt_source_img_f</span><span class="p">)</span>

<span class="c1"># Convert coordinates to pixel units</span>
<span class="n">um_per_px</span> <span class="o">=</span> <span class="n">pt_source_slide</span><span class="o">.</span><span class="n">reader</span><span class="o">.</span><span class="n">scale_physical_size</span><span class="p">(</span><span class="n">COORD_LEVEL</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">bbox_xy_px</span> <span class="o">=</span> <span class="n">bbox_xy_um</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">um_per_px</span><span class="p">)</span>

<span class="c1"># Warp coordinates to position in registered slides</span>
<span class="n">bbox_xy_in_registered_img</span> <span class="o">=</span> <span class="n">pt_source_slide</span><span class="o">.</span><span class="n">warp_xy</span><span class="p">(</span><span class="n">bbox_xy_px</span><span class="p">,</span>
                                                    <span class="n">slide_level</span><span class="o">=</span><span class="n">COORD_LEVEL</span><span class="p">,</span>
                                                    <span class="n">pt_level</span><span class="o">=</span><span class="n">COORD_LEVEL</span><span class="p">)</span>

<span class="n">bbox_xywh_in_registered_img</span> <span class="o">=</span> <span class="n">warp_tools</span><span class="o">.</span><span class="n">xy2bbox</span><span class="p">(</span><span class="n">bbox_xy_in_registered_img</span><span class="p">)</span>
<span class="n">bbox_xywh_in_registered_img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">bbox_xywh_in_registered_img</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># Create directory where images will be saved</span>
<span class="n">dst_dir</span> <span class="o">=</span> <span class="s2">&quot;./expected_results/roi&quot;</span>
<span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">dst_dir</span><span class="p">)</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Warp each slide and slice the ROI from it using each pyips.Image&#39;s &quot;extract_area&quot; method.</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">slide</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">registrar</span><span class="o">.</span><span class="n">slide_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
    <span class="n">warped_slide</span> <span class="o">=</span> <span class="n">slide</span><span class="o">.</span><span class="n">warp_slide</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">COORD_LEVEL</span><span class="p">)</span>
    <span class="n">roi_vips</span> <span class="o">=</span> <span class="n">warped_slide</span><span class="o">.</span><span class="n">extract_area</span><span class="p">(</span><span class="o">*</span><span class="n">bbox_xywh_in_registered_img</span><span class="p">)</span>
    <span class="n">roi_img</span> <span class="o">=</span> <span class="n">warp_tools</span><span class="o">.</span><span class="n">vips2numpy</span><span class="p">(</span><span class="n">roi_vips</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">roi_img</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">slide</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>

<span class="n">fig</span><span class="o">.</span><span class="n">delaxes</span><span class="p">(</span><span class="n">ax</span><span class="p">[</span><span class="mi">5</span><span class="p">])</span> <span class="c1"># Only 5 images, so remove 6th subplot</span>
<span class="n">out_f</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dst_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">registrar</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_roi.png&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">out_f</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># Opening the slide initialized the JVM, so it needs to be killed</span>
<span class="n">registration</span><span class="o">.</span><span class="n">kill_jvm</span><span class="p">()</span>
</pre></div>
</div>
<p>The extracted and registered ROI are shown below:</p>
<img alt="https://github.com/MathOnco/valis/raw/main/examples/expected_results/roi/ihc_roi.png" src="https://github.com/MathOnco/valis/raw/main/examples/expected_results/roi/ihc_roi.png" />
</section>
<section id="converting-slides-to-ome-tiff">
<h2>Converting slides to ome.tiff<a class="headerlink" href="#converting-slides-to-ome-tiff" title="Permalink to this headline">¶</a></h2>
<p>In addition to registering slide, VALIS can convert slides to ome.tiff, maintaining the original metadata. If the original is image is not RGB, the option <code class="code docutils literal notranslate"><span class="pre">perceputally_uniform_channel_colors=True</span></code> can be used to give each channel a perceptually uniform color, derived from the <a class="reference external" href="https://www.osapublishing.org/DirectPDFAccess/5166548C-BD18-487D-8601630F3A343883_368272/oe-25-13-15131.pdf?da=1&amp;id=368272&amp;seq=0&amp;mobile=no">JzAzBz</a> colorspace. An advantage of using perceptually uniform colors is that markers should appear brighter only if there is higher expression, not because the color (such as yellow) is perceived to be brighter.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">valis</span> <span class="kn">import</span> <span class="n">slide_io</span>
<span class="n">slide_src_f</span> <span class="o">=</span> <span class="s2">&quot;path/to/slide</span>
<span class="n">converted_slide_f</span> <span class="o">=</span> <span class="s2">&quot;converted.ome.tiff&quot;</span>
<span class="n">slide_io</span><span class="o">.</span><span class="n">convert_to_ome_tiff</span><span class="p">(</span><span class="n">slide_src_f</span><span class="p">,</span>
                            <span class="n">converted_slide_f</span><span class="p">,</span>
                            <span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                            <span class="n">perceputally_uniform_channel_colors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">slide_io</span><span class="o">.</span><span class="n">kill_jvm</span><span class="p">()</span>
</pre></div>
</div>
<img alt="https://github.com/MathOnco/valis/raw/main/docs/_images/pu_color_mplex.png" src="https://github.com/MathOnco/valis/raw/main/docs/_images/pu_color_mplex.png" />
</section>
<section id="reading-slides">
<h2>Reading slides<a class="headerlink" href="#reading-slides" title="Permalink to this headline">¶</a></h2>
<p>VALIS also provides functions to read images/slides using libvips, Bio-Formats, or Openslide. These reader objects also contain some of the slide’s metatadata. The <code class="code docutils literal notranslate"><span class="pre">slide2image</span></code> method will return a numpy array of the slide, while <code class="code docutils literal notranslate"><span class="pre">slide2vips</span></code> will return a <code class="code docutils literal notranslate"><span class="pre">pyvips.Image</span></code>, which is ideal when working with very large images. The user can specify the pyramid level, series, and bounding box, but the default is level 0, series 0, and the whole image. See <code class="code docutils literal notranslate"><span class="pre">slide_io.SlideReader</span></code> and <code class="code docutils literal notranslate"><span class="pre">slide_io.MetaData</span></code> for more details.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">valis</span> <span class="kn">import</span> <span class="n">slide_io</span>
<span class="n">slide_src_f</span> <span class="o">=</span> <span class="s2">&quot;path/to/slide.svs</span>
<span class="n">series</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># Get reader for slide format</span>
<span class="n">reader_cls</span> <span class="o">=</span> <span class="n">slide_io</span><span class="o">.</span><span class="n">get_slide_reader</span><span class="p">(</span><span class="n">slide_src_f</span><span class="p">,</span> <span class="n">series</span><span class="o">=</span><span class="n">series</span><span class="p">)</span> <span class="c1">#Get appropriate slide reader class</span>
<span class="n">reader</span> <span class="o">=</span> <span class="n">reader_cls</span><span class="p">(</span><span class="n">slide_src_f</span><span class="p">,</span> <span class="n">series</span><span class="o">=</span><span class="n">series</span><span class="p">)</span> <span class="c1"># Instantiate reader</span>

<span class="c1">#Get size of images in each pyramid level (width, height)</span>
<span class="n">pyramid_level_sizes_wh</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">slide_dimensions</span>

<span class="c1"># Get physical units per pixel</span>
<span class="n">pixel_physical_size_xyu</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">pixel_physical_size_xyu</span>

<span class="c1"># Get channel names (None if image is RGB)</span>
<span class="n">channel_names</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">channel_names</span>

<span class="c1"># Get original xml metadata</span>
<span class="n">original_xml</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">original_xml</span>

<span class="c1"># Get smaller pyramid level 3 as a numpy array</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">slide2image</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Get full resolution image as a pyvips.Image</span>
<span class="n">full_rez_vips</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">slide2vips</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Slice region of interest from level 0 and return as numpy array</span>
<span class="n">roi_img</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">slide2image</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">xywh</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">))</span>

<span class="n">slide_io</span><span class="o">.</span><span class="n">kill_jvm</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="warping-slides-with-custom-transforms">
<h2>Warping slides with custom transforms<a class="headerlink" href="#warping-slides-with-custom-transforms" title="Permalink to this headline">¶</a></h2>
<p>VALIS provides the functions to apply transformations to slides and then save the registered slide, meaning the user can provide their own transformation parameters. In this example, <cite>src_f</cite> is the path to the file associated with the slide, <cite>M</cite> is the inverse rigid registration matrix, and <cite>bk_dxdy</cite> is a list of the backwards non-rigid displacement fields (i.e. [dx, dy]), each found by aligning the fixed/target image to the moving/source image.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The transformations will need to be inverted if they were found the other way around, i.e. aligning the moving/source image to the fixed/target image. Transformation matrices can be inverted using <code class="code docutils literal notranslate"><span class="pre">np.linalg.inv</span></code>, while displacement fields can be inverted using <code class="code docutils literal notranslate"><span class="pre">warp_tools.get_inverse_field</span></code>.</p>
</div>
<p>One may also need to provide the shape of the image (row, col) used to find the rigid transformation (if applicable), which is the <cite>transformation_src_shape_rc</cite> argument. In this case, it is the shape of the processed image that was used during feature detection. Similarly, <cite>transformation_dst_shape_rc</cite> is the shape of the registered image, in this case the shape of the processed image after being warped. Finally, <cite>aligned_slide_shape_rc</cite> is the shape of the warped slide. Please see <code class="code docutils literal notranslate"><span class="pre">slide_io.warp_and_save_slide</span></code> for more information and options, like defining background color, crop area, etc..</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">valis</span> <span class="kn">import</span> <span class="n">slide_io</span>

<span class="c1"># Read and warp the slide #</span>
<span class="n">slide_src_f</span> <span class="o">=</span> <span class="s2">&quot;path/to/slide</span>
<span class="n">dst_f</span> <span class="o">=</span> <span class="s2">&quot;path/to/write/slide.ome.tiff&quot;</span>
<span class="n">series</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">pyramid_level</span><span class="o">=</span><span class="mi">0</span>

<span class="n">slide_io</span><span class="o">.</span><span class="n">warp_and_save_slide</span><span class="p">(</span><span class="n">src_f</span><span class="o">=</span><span class="n">slide_src_f</span><span class="p">,</span>
                             <span class="n">dst_f</span><span class="o">=</span><span class="n">dst_f</span><span class="p">,</span>
                             <span class="n">transformation_src_shape_rc</span><span class="o">=</span><span class="n">processed_img_shape_rc</span><span class="p">,</span>
                             <span class="n">transformation_dst_shape_rc</span><span class="o">=</span><span class="n">small_registered_img_shape_rc</span><span class="p">,</span>
                             <span class="n">aligned_slide_shape_rc</span><span class="o">=</span><span class="n">aligned_slide_shape_rc</span><span class="p">,</span>
                             <span class="n">level</span><span class="o">=</span><span class="n">pyramid_level</span><span class="p">,</span>
                             <span class="n">series</span><span class="o">=</span><span class="n">series</span><span class="p">,</span>
                             <span class="n">M</span><span class="o">=</span><span class="n">M</span><span class="p">,</span>
                             <span class="n">dxdy</span><span class="o">=</span><span class="n">dxdy</span><span class="p">)</span>


<span class="n">slide_io</span><span class="o">.</span><span class="n">kill_jvm</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="using-non-defaults">
<h2>Using non-defaults<a class="headerlink" href="#using-non-defaults" title="Permalink to this headline">¶</a></h2>
<p>The defaults used by VALIS work well, but one may wish to try some other values/class, and/or create their own affine optimizer, feature detector, non-rigid registrar, etc… This examples shows how to conduct registration using non-default values</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This example assumes that <a class="reference external" href="https://simpleelastix.readthedocs.io/GettingStarted.html">SimpleElastix</a> has been installed.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">valis</span> <span class="kn">import</span> <span class="n">registration</span><span class="p">,</span> <span class="n">feature_detectors</span><span class="p">,</span> <span class="n">non_rigid_registrars</span><span class="p">,</span> <span class="n">affine_optimizer</span>
<span class="n">slide_src_dir</span> <span class="o">=</span> <span class="s2">&quot;path/to/slides&quot;</span>
<span class="n">results_dst_dir</span> <span class="o">=</span> <span class="s2">&quot;./slide_registration_example_non_defaults&quot;</span>
<span class="n">registered_slide_dst_dir</span> <span class="o">=</span> <span class="s2">&quot;./slide_registration_example/registered_slides&quot;</span>


<span class="c1"># Select feature detector, affine optimizer, and non-rigid registration method.</span>
<span class="c1"># Will use KAZE for feature detection and description</span>
<span class="c1"># SimpleElastix will be used for non-rigid warping and affine optimization</span>
<span class="n">feature_detector_cls</span> <span class="o">=</span> <span class="n">feature_detectors</span><span class="o">.</span><span class="n">KazeFD</span>
<span class="n">non_rigid_registrar_cls</span> <span class="o">=</span> <span class="n">non_rigid_registrars</span><span class="o">.</span><span class="n">SimpleElastixWarper</span>
<span class="n">affine_optimizer_cls</span> <span class="o">=</span> <span class="n">affine_optimizer</span><span class="o">.</span><span class="n">AffineOptimizerMattesMI</span>

<span class="c1"># Create a Valis object and use it to register the slides in slide_src_dir</span>
<span class="n">registrar</span> <span class="o">=</span> <span class="n">registration</span><span class="o">.</span><span class="n">Valis</span><span class="p">(</span><span class="n">slide_src_dir</span><span class="p">,</span> <span class="n">results_dst_dir</span><span class="p">,</span>
                               <span class="n">feature_detector_cls</span><span class="o">=</span><span class="n">feature_detector_cls</span><span class="p">,</span>
                               <span class="n">affine_optimizer_cls</span><span class="o">=</span><span class="n">affine_optimizer_cls</span><span class="p">,</span>
                               <span class="n">non_rigid_registrar_cls</span><span class="o">=</span><span class="n">non_rigid_registrar_cls</span><span class="p">)</span>


<span class="n">rigid_registrar</span><span class="p">,</span> <span class="n">non_rigid_registrar</span><span class="p">,</span> <span class="n">error_df</span> <span class="o">=</span> <span class="n">registrar</span><span class="o">.</span><span class="n">register</span><span class="p">()</span>

<span class="n">registration</span><span class="o">.</span><span class="n">kill_jvm</span><span class="p">()</span> <span class="c1"># Kill the JVM</span>
</pre></div>
</div>
</section>
</section>
<section id="change-log">
<h1><a class="toc-backref" href="#id6">Change Log</a><a class="headerlink" href="#change-log" title="Permalink to this headline">¶</a></h1>
<section id="version-1-0-0rc11-august-26-2022">
<h2>Version 1.0.0rc11 (August 26, 2022)<a class="headerlink" href="#version-1-0-0rc11-august-26-2022" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>Fixed bug when providing rigid transformations (Issue 14, <a class="reference external" href="https://github.com/MathOnco/valis/issues/14">https://github.com/MathOnco/valis/issues/14</a>).</p></li>
<li><p>Can now warp one image onto another, making it possible to transfer annotations using labeled images (Issue 13 <a class="reference external" href="https://github.com/MathOnco/valis/issues/13">https://github.com/MathOnco/valis/issues/13</a>). This can be done using a Slide object’s <code class="code docutils literal notranslate"><span class="pre">warp_img_from_to</span></code> method. See example in examples/warp_annotation_image.py</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">ImageProcesser</span></code> objects now have a  <code class="code docutils literal notranslate"><span class="pre">create_mask</span></code> function that is used to build the masks for rigid registration. These are then used to create the mask used for non-rigid registration, where they are combined such that the final mask is where they overlap and/or touch.</p></li>
<li><p>Non-rigid registration performed on higher resolution version of the image. The area inside the non-rigid mask is sliced out such that it encompasses the area inside the mask but has a maximum dimension of  <code class="code docutils literal notranslate"><span class="pre">Valis.max_non_rigid_registartion_dim_px</span></code>. This can improve accuracy when the tissue is only a small part of the image. If masks aren’t created, this region will be where all of the slides overalp.</p></li>
<li><p>Version used to submit results to the ACROBAT Grand Challenge. Code used to perform registration can be found in examples/acrobat_grand_challenge.py. This example also shows how to use and create a custom <code class="code docutils literal notranslate"><span class="pre">ImageProcesser</span></code> and perform micro-registration with a mask.</p></li>
</ol>
</section>
<section id="version-1-0-0rc10-august-11-2022">
<h2>Version 1.0.0rc10 (August 11, 2022)<a class="headerlink" href="#version-1-0-0rc10-august-11-2022" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>Fixed compatibility with updated interpolation package (Issue 12).</p></li>
</ol>
</section>
<section id="version-1-0-0rc9-august-4-2022">
<h2>Version 1.0.0rc9 (August 4, 2022)<a class="headerlink" href="#version-1-0-0rc9-august-4-2022" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>Reduced memory usage for micro-registration and warping. No longer copying memory before warping, and large displacement fields saved as .tiff images instead of .vips images.</p></li>
<li><p>Reduced unwanted accumulation of displacements</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">viz.draw_matches</span></code> now returns an image instead of a matplotlib pyplot</p></li>
<li><p>Pull request 9-11 bug fixes (many thanks to crobbins327 and zindy): Not converting uint16 to uint8 when reading using Bio-Formats or pyvips; fixed rare error when filtering neighbor matches; <code class="code docutils literal notranslate"><span class="pre">viz.get_grid</span></code> consistent on Linux and Windows; typos.</p></li>
</ol>
</section>
<section id="version-1-0-0rc8-july-1-2022">
<h2>Version 1.0.0rc8 (July 1, 2022)<a class="headerlink" href="#version-1-0-0rc8-july-1-2022" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>Now compatible with single channel images. These images are treated as immunofluorescent images, and so custom pre-processing classes and arguments should be passed to <code class="code docutils literal notranslate"><span class="pre">if_processing_cls</span></code> and <code class="code docutils literal notranslate"><span class="pre">if_processing_kwargs</span></code> of the <code class="code docutils literal notranslate"><span class="pre">Valis.register</span></code> method. The current method will perform adaptive histogram equalization and scales the image to 0-255 (see <code class="code docutils literal notranslate"><span class="pre">preprocessing.ChannelGetter</span></code>). Also, since it isn’t possible to determine if the single channel image is a greyscale RGB (light background) or single channel immunofluorescence (or similar with dark background), the background color will not be estimated, meaning that in the registered image the area outside of the warped image will be black (as opposed to the estimated background color). Tissue masks will still be created, but if it seems they are not covering enough area then try setting <code class="code docutils literal notranslate"><span class="pre">create_masks</span></code> to <cite>False</cite> when initializing the <code class="code docutils literal notranslate"><span class="pre">Valis</span></code> object.</p></li>
</ol>
</section>
<section id="version-1-0-0rc7-june-27-2022">
<h2>Version 1.0.0rc7 (June 27, 2022)<a class="headerlink" href="#version-1-0-0rc7-june-27-2022" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>Can set size of image to be used for non-rigid registration, which may help improve aligment of micro-architectural structures. However this will increase the amount of time it takes to perform non-rigid registration, and will increase amount of memory used during registration, and the size of the pickled :code: <cite>Valis</cite> object. To change this value, set the <code class="code docutils literal notranslate"><span class="pre">max_non_rigid_registartion_dim_px</span></code> parameter when initializing the <code class="code docutils literal notranslate"><span class="pre">Valis</span></code> object.</p></li>
<li><p>Can now do a second non-rigid registartion on higher resolution images, including the full resolution one. This can be done with the <code class="code docutils literal notranslate"><span class="pre">Valis.register_micro</span></code>. If the images are large, they will be sliced into tiles, and then each tile registered with one another. The deformation fields will be saved separately as .vips images within the data folder.</p></li>
<li><p>Added <code class="code docutils literal notranslate"><span class="pre">registration.load_registrar</span></code> function to open a <code class="code docutils literal notranslate"><span class="pre">Valis</span></code> object. This should be used instead of <cite>pickle.load</cite>.</p></li>
<li><p>Creating and applying tissue masks before registration. This improves image normalization, reduces the number of poor feature matches, and helps remove unwanted non-rigid deformations (especially around the image edges), all of which improve alignment accuracy. This step can be skipped by setting <code class="code docutils literal notranslate"><span class="pre">create_masks</span></code> to <cite>False</cite> when initializing the <code class="code docutils literal notranslate"><span class="pre">Valis</span></code> object.</p></li>
<li><p>Now possible to directly non-rigidly align to the reference image specified by <code class="code docutils literal notranslate"><span class="pre">reference_img_f</span></code>. This can be done by setting <code class="code docutils literal notranslate"><span class="pre">align_to_reference</span></code> to <cite>True</cite> when initializing the <code class="code docutils literal notranslate"><span class="pre">Valis</span></code> object. The default is <cite>False</cite>, which means images will be aligned serially towards the reference image.  This option is also available with <code class="code docutils literal notranslate"><span class="pre">Valis.register_micro</span></code>, meaning that one could do a second alignment, but aligning all directly to a reference image.</p></li>
<li><p>RANSAC filtered matches found for rigid registration undergo second round of filtering, this time using Tukey’s method to remove matches whose distance after  being warped would be considered outliers.</p></li>
<li><p>Now have option off whether or not to compose non-rigid transformations. This can be set specifying the <code class="code docutils literal notranslate"><span class="pre">compose_non_rigid</span></code> argument when initialzing the <cite>Valis</cite> object.</p></li>
<li><p>Can provide rigid transformation matrices by passing in a dictionary to the <code class="code docutils literal notranslate"><span class="pre">do_rigid</span></code> parameter when initializing the <code class="code docutils literal notranslate"><span class="pre">Valis</span></code> object. Setting <code class="code docutils literal notranslate"><span class="pre">do_rigid</span></code> to <cite>False</cite> will completely skip the rigid registration step. See the documentation for initializing the <cite>Valis</cite> object for more details.</p></li>
<li><p>Added examples of how to read slides and use custom transforms</p></li>
<li><p>Benchmarked using ANHIR Grand Challenge dataset and posted results on leaderboard.</p></li>
<li><p>bioformats_jar has been deprecated, so added support for its replacement, scyjava. However, the default behavior will be to use the bioformats_jar JAR file if it’s already been installed. One can also now specify the JAR file when calling <code class="code docutils literal notranslate"><span class="pre">init_jvm</span></code>.</p></li>
</ol>
</section>
<section id="version-1-0-0rc6-april-18-2022">
<h2>Version 1.0.0rc6 (April 18, 2022)<a class="headerlink" href="#version-1-0-0rc6-april-18-2022" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>More accurate color mixing with fewer artifacts. Affects overlap images and pseudo-colored multi-channel images.</p></li>
<li><p>Initializing  ‘is_flattended_pyramid’ with False. Pull request #6</p></li>
<li><p>Reformatting flattened pyramids to have same datatype as that in metadata.</p></li>
<li><p>Saving all images using pyvips. Should be faster.</p></li>
<li><p>Using Bio-Formats to read non-RGB ome-tiff. Addresses an issue where converting non-RGB ome-tiff to numpy was very slow.</p></li>
</ol>
</section>
<section id="version-1-0-0rc5-april-5-2022">
<h2>Version 1.0.0rc5 (April 5, 2022)<a class="headerlink" href="#version-1-0-0rc5-april-5-2022" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>Can provide a reference image that the others will be aligned towards. To do this, when initializinig the Valis object, set the <code class="code docutils literal notranslate"><span class="pre">reference_img_f</span></code> argument to be the file name of the reference image. If not set by the user, the reference image will be set as the one at the center of the ordered image stack</p></li>
<li><p>Both non-rigid and rigid now align <em>towards</em> a reference image, meaning that reference image will have neither rigid nor non-rigid transformations applied to it.</p></li>
<li><p>Two cropping methods. First option is to crop seach registered slides to contain only the areas where all registered images overlap. The second option is to crop the registered slide to contain only the area that intersects with the reference image. It is also possible to not crop an image/slide.</p></li>
<li><p>Images are now cropped during the warp, not after, and so is now faster and requires less memory. For example, on a 2018 MacBook Pro with a 2.6 GHz Intel Core i7 processor, it takes 2-3 minutes to warp and save a 41399 x 43479 RGB image.</p></li>
<li><p>Warping of images and slides done using the same function, built around pyvips. Faster, more consistent, and should prevent excessive memory usage.</p></li>
<li><p>Fixed bug that caused a crash when warping large ome.tiff images.</p></li>
<li><p>Read slides and images using pyvips whenever possible.</p></li>
<li><p>Background color now automatically set to be same as the brightest (IHC) or darkest (IF) pixel in the image. Because of this, the “bg_color” argument in the slide warping functions was removed.</p></li>
<li><p>Reduced accumulation of unwanted non-rigid deformations</p></li>
<li><p>Displacement fields drawn on top of non-rigid registered image to help determine where the deformations occured.</p></li>
<li><p>If a slide has multiple series, and a series is not specficed, the slide reader will read the series containing the largest image.</p></li>
</ol>
</section>
<section id="license">
<h2>License<a class="headerlink" href="#license" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="LICENSE.txt">MIT</a> © 2021-2022 Chandler Gatenbee</p>
</section>
</section>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, Chandler Gatenbee.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>